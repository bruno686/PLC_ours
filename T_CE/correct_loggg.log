yelp correct training
arguments: Namespace(batch_size=1024, dataset='yelp', drop_rate=0.2, dropout=0.0, epochs=10, eval_freq=2000, exponent=1, factor_num=32, gpu='1', lr=0.001, model='NeuMF-end', num_gradual=30000, num_layers=3, num_ng=1, out=True, top_k=['[', '5', '0', ',', '1', '0', '0', ']']) 
config model NeuMF-end
config data path ../data/yelp/
config model path /home/hezhuangzhuang/DenoisingRec/T_CE/models/yelp/
user, item num
45548 57396
data loaded! user_num:45548, item_num:57396 train_data_len:1672520 test_user_num:45525
epoch: 0, iter: 2000, loss:0.5426334142684937
################### EVAL ######################
Eval loss:229.900146484375
epoch: 1, iter: 4000, loss:0.3720168471336365
################### EVAL ######################
Eval loss:169.5995330810547
epoch: 1, iter: 6000, loss:0.31729236245155334
################### EVAL ######################
Eval loss:152.0457763671875
epoch: 2, iter: 8000, loss:0.2571025788784027
################### EVAL ######################
Eval loss:154.7969970703125
epoch: 3, iter: 10000, loss:0.204490065574646
################### EVAL ######################
Eval loss:180.46180725097656
epoch: 3, iter: 12000, loss:0.20401406288146973
################### EVAL ######################
Eval loss:179.92372131347656
epoch: 4, iter: 14000, loss:0.1676013320684433
################### EVAL ######################
Eval loss:229.15567016601562
epoch: 4, iter: 16000, loss:0.14405818283557892
################### EVAL ######################
Eval loss:221.64816284179688
yelp correct training
arguments: Namespace(batch_size=1024, dataset='yelp', drop_rate=0.2, dropout=0.0, epochs=10, eval_freq=2000, exponent=1, factor_num=32, gpu='0', lr=0.001, model='NeuMF-end', num_gradual=30000, num_layers=3, num_ng=1, out=True, top_k=[50, 100]) 
config model NeuMF-end
config data path ../data/yelp/
config model path /home/hezhuangzhuang/DenoisingRec/T_CE/models/yelp/
user, item num
45548 57396
data loaded! user_num:45548, item_num:57396 train_data_len:1672520 test_user_num:45525
epoch: 0, iter: 2000, loss:0.5426334142684937
################### EVAL ######################
Eval loss:229.900146484375
epoch: 1, iter: 4000, loss:0.3720168471336365
################### EVAL ######################
Eval loss:169.5995330810547
epoch: 1, iter: 6000, loss:0.31729236245155334
################### EVAL ######################
Eval loss:152.0457763671875
epoch: 2, iter: 8000, loss:0.2571025788784027
################### EVAL ######################
Eval loss:154.7969970703125
epoch: 3, iter: 10000, loss:0.204490065574646
################### EVAL ######################
Eval loss:180.46180725097656
epoch: 3, iter: 12000, loss:0.20401406288146973
################### EVAL ######################
Eval loss:179.92372131347656
epoch: 4, iter: 14000, loss:0.1676013320684433
################### EVAL ######################
Eval loss:229.15567016601562
epoch: 4, iter: 16000, loss:0.14405818283557892
################### EVAL ######################
Eval loss:221.64816284179688
epoch: 5, iter: 18000, loss:0.12386471033096313
################### EVAL ######################
Eval loss:277.4385070800781
epoch: 6, iter: 20000, loss:0.08785204589366913
################### EVAL ######################
Eval loss:334.40625
epoch: 6, iter: 22000, loss:0.10509374737739563
################### EVAL ######################
Eval loss:323.8102111816406
epoch: 7, iter: 24000, loss:0.13812744617462158
################### EVAL ######################
Eval loss:381.5446472167969
epoch: 7, iter: 26000, loss:0.1014455258846283
################### EVAL ######################
Eval loss:366.7802734375
epoch: 8, iter: 28000, loss:0.07615607976913452
################### EVAL ######################
Eval loss:414.6835632324219
epoch: 9, iter: 30000, loss:0.08143654465675354
################### EVAL ######################
Eval loss:501.1678466796875
epoch: 9, iter: 32000, loss:0.08242183923721313
################### EVAL ######################
Eval loss:468.7750244140625
############################## Training End. ##############################
################### TEST ######################
Recall 0.0758-0.1239
NDCG 0.0314-0.0422
amazon correct training
arguments: Namespace(batch_size=1024, dataset='amazon_book', drop_rate=0.2, dropout=0.0, epochs=10, eval_freq=2000, exponent=1, factor_num=32, gpu='0', lr=0.001, model='NeuMF-end', num_gradual=30000, num_layers=3, num_ng=1, out=True, top_k=[50, 100]) 
config model NeuMF-end
config data path ../data/amazon_book/
config model path /home/hezhuangzhuang/DenoisingRec/T_CE/models/amazon_book/
user, item num
80464 98663
data loaded! user_num:80464, item_num:98663 train_data_len:2714021 test_user_num:80349
epoch: 0, iter: 2000, loss:0.6128747463226318
################### EVAL ######################
Eval loss:406.3522644042969
epoch: 0, iter: 4000, loss:0.5255219340324402
################### EVAL ######################
Eval loss:349.6194152832031
epoch: 1, iter: 6000, loss:0.4051913619041443
################### EVAL ######################
Eval loss:308.88916015625
epoch: 1, iter: 8000, loss:0.3682325482368469
################### EVAL ######################
Eval loss:283.13775634765625
epoch: 1, iter: 10000, loss:0.369365394115448
################### EVAL ######################
Eval loss:263.0207214355469
epoch: 2, iter: 12000, loss:0.25881683826446533
################### EVAL ######################
Eval loss:285.21221923828125
epoch: 2, iter: 14000, loss:0.29053235054016113
################### EVAL ######################
Eval loss:278.93096923828125
epoch: 3, iter: 16000, loss:0.18367919325828552
################### EVAL ######################
Eval loss:313.2138671875
epoch: 3, iter: 18000, loss:0.17657339572906494
################### EVAL ######################
Eval loss:320.7159118652344
epoch: 3, iter: 20000, loss:0.20240750908851624
################### EVAL ######################
Eval loss:320.93389892578125
epoch: 4, iter: 22000, loss:0.1243087574839592
################### EVAL ######################
Eval loss:385.4178161621094
epoch: 4, iter: 24000, loss:0.15861991047859192
################### EVAL ######################
Eval loss:379.5267639160156
epoch: 4, iter: 26000, loss:0.18096676468849182
################### EVAL ######################
Eval loss:378.1731872558594
epoch: 5, iter: 28000, loss:0.1498909741640091
################### EVAL ######################
Eval loss:471.21502685546875
epoch: 5, iter: 30000, loss:0.09812146425247192
################### EVAL ######################
Eval loss:443.0838928222656
epoch: 6, iter: 32000, loss:0.09717065095901489
################### EVAL ######################
Eval loss:544.82421875
epoch: 6, iter: 34000, loss:0.10171432793140411
################### EVAL ######################
Eval loss:528.7589721679688
epoch: 6, iter: 36000, loss:0.12859231233596802
################### EVAL ######################
Eval loss:552.85009765625
epoch: 7, iter: 38000, loss:0.07663708925247192
################### EVAL ######################
Eval loss:638.7730712890625
epoch: 7, iter: 40000, loss:0.08320281654596329
################### EVAL ######################
Eval loss:590.3145141601562
epoch: 7, iter: 42000, loss:0.13373945653438568
################### EVAL ######################
Eval loss:600.3804931640625
epoch: 8, iter: 44000, loss:0.10767394304275513
################### EVAL ######################
Eval loss:738.4500732421875
epoch: 8, iter: 46000, loss:0.13829460740089417
################### EVAL ######################
Eval loss:678.6792602539062
epoch: 9, iter: 48000, loss:0.06502832472324371
################### EVAL ######################
Eval loss:801.2380981445312
epoch: 9, iter: 50000, loss:0.12131325900554657
################### EVAL ######################
Eval loss:790.554931640625
epoch: 9, iter: 52000, loss:0.09517938643693924
################### EVAL ######################
Eval loss:753.604736328125
############################## Training End. ##############################
################### TEST ######################
Recall 0.0443-0.0708
NDCG 0.0185-0.0245
amazon correct training
arguments: Namespace(batch_size=1024, dataset='amazon_book', drop_rate=0.2, dropout=0.0, epochs=10, eval_freq=2000, exponent=1, factor_num=32, gpu='0', lr=0.001, model='NeuMF-end', num_gradual=30000, num_layers=3, num_ng=1, out=True, top_k=[3, 20]) 
config model NeuMF-end
config data path ../data/amazon_book/
config model path /home/hezhuangzhuang/DenoisingRec/T_CE/models/amazon_book/
user, item num
80464 98663
data loaded! user_num:80464, item_num:98663 train_data_len:2714021 test_user_num:80349
epoch: 0, iter: 2000, loss:0.6128747463226318
################### EVAL ######################
Eval loss:406.3522644042969
epoch: 0, iter: 4000, loss:0.5255219340324402
################### EVAL ######################
Eval loss:349.6194152832031
epoch: 1, iter: 6000, loss:0.4051913619041443
################### EVAL ######################
Eval loss:308.88916015625
epoch: 1, iter: 8000, loss:0.3682325482368469
################### EVAL ######################
Eval loss:283.13775634765625
epoch: 1, iter: 10000, loss:0.369365394115448
################### EVAL ######################
Eval loss:263.0207214355469
epoch: 2, iter: 12000, loss:0.25881683826446533
################### EVAL ######################
Eval loss:285.21221923828125
epoch: 2, iter: 14000, loss:0.29053235054016113
################### EVAL ######################
Eval loss:278.93096923828125
epoch: 3, iter: 16000, loss:0.18367919325828552
################### EVAL ######################
Eval loss:313.2138671875
epoch: 3, iter: 18000, loss:0.17657339572906494
################### EVAL ######################
Eval loss:320.7159118652344
epoch: 3, iter: 20000, loss:0.20240750908851624
################### EVAL ######################
Eval loss:320.93389892578125
epoch: 4, iter: 22000, loss:0.1243087574839592
################### EVAL ######################
Eval loss:385.4178161621094
epoch: 4, iter: 24000, loss:0.15861991047859192
################### EVAL ######################
Eval loss:379.5267639160156
epoch: 4, iter: 26000, loss:0.18096676468849182
################### EVAL ######################
Eval loss:378.1731872558594
epoch: 5, iter: 28000, loss:0.1498909741640091
################### EVAL ######################
Eval loss:471.21502685546875
epoch: 5, iter: 30000, loss:0.09812146425247192
################### EVAL ######################
Eval loss:443.0838928222656
epoch: 6, iter: 32000, loss:0.09717065095901489
################### EVAL ######################
Eval loss:544.82421875
epoch: 6, iter: 34000, loss:0.10171432793140411
################### EVAL ######################
Eval loss:528.7589721679688
epoch: 6, iter: 36000, loss:0.12859231233596802
################### EVAL ######################
Eval loss:552.85009765625
epoch: 7, iter: 38000, loss:0.07663708925247192
################### EVAL ######################
Eval loss:638.7730712890625
epoch: 7, iter: 40000, loss:0.08320281654596329
################### EVAL ######################
Eval loss:590.3145141601562
epoch: 7, iter: 42000, loss:0.13373945653438568
################### EVAL ######################
Eval loss:600.3804931640625
epoch: 8, iter: 44000, loss:0.10767394304275513
################### EVAL ######################
Eval loss:738.4500732421875
epoch: 8, iter: 46000, loss:0.13829460740089417
################### EVAL ######################
Eval loss:678.6792602539062
epoch: 9, iter: 48000, loss:0.06502832472324371
################### EVAL ######################
Eval loss:801.2380981445312
epoch: 9, iter: 50000, loss:0.12131325900554657
################### EVAL ######################
Eval loss:790.554931640625
epoch: 9, iter: 52000, loss:0.09517938643693924
################### EVAL ######################
Eval loss:753.604736328125
############################## Training End. ##############################
################### TEST ######################
Recall 0.0057-0.0230
NDCG 0.0074-0.0129
yelp correct training
arguments: Namespace(batch_size=1024, dataset='amazon_book', drop_rate=0.2, dropout=0.0, epochs=10, eval_freq=2000, exponent=1, factor_num=32, gpu='1', lr=0.001, model='NeuMF-end', num_gradual=30000, num_layers=3, num_ng=1, out=True, top_k=[50, 100]) 
config model NeuMF-end
config data path ../data/amazon_book/
config model path /home/hezhuangzhuang/DenoisingRec/T_CE/models/amazon_book/
user, item num
80464 98663
data loaded! user_num:80464, item_num:98663 train_data_len:2714021 test_user_num:80349
epoch: 0, iter: 2000, loss:0.6128747463226318
################### EVAL ######################
Eval loss:406.3522644042969
epoch: 0, iter: 4000, loss:0.5255219340324402
################### EVAL ######################
Eval loss:349.6194152832031
epoch: 1, iter: 6000, loss:0.4051913619041443
################### EVAL ######################
Eval loss:308.88916015625
epoch: 1, iter: 8000, loss:0.3682325482368469
################### EVAL ######################
Eval loss:283.13775634765625
epoch: 1, iter: 10000, loss:0.369365394115448
################### EVAL ######################
Eval loss:263.0207214355469
epoch: 2, iter: 12000, loss:0.25881683826446533
################### EVAL ######################
Eval loss:285.21221923828125
epoch: 2, iter: 14000, loss:0.29053235054016113
################### EVAL ######################
Eval loss:278.93096923828125
epoch: 3, iter: 16000, loss:0.18367919325828552
################### EVAL ######################
Eval loss:313.2138671875
epoch: 3, iter: 18000, loss:0.17657339572906494
################### EVAL ######################
Eval loss:320.7159118652344
epoch: 3, iter: 20000, loss:0.20240750908851624
################### EVAL ######################
Eval loss:320.93389892578125
epoch: 4, iter: 22000, loss:0.1243087574839592
################### EVAL ######################
Eval loss:385.4178161621094
epoch: 4, iter: 24000, loss:0.15861991047859192
################### EVAL ######################
Eval loss:379.5267639160156
epoch: 4, iter: 26000, loss:0.18096676468849182
################### EVAL ######################
Eval loss:378.1731872558594
epoch: 5, iter: 28000, loss:0.1498909741640091
################### EVAL ######################
Eval loss:471.21502685546875
epoch: 5, iter: 30000, loss:0.09812146425247192
################### EVAL ######################
Eval loss:443.0838928222656
epoch: 6, iter: 32000, loss:0.09717065095901489
################### EVAL ######################
Eval loss:544.82421875
epoch: 6, iter: 34000, loss:0.10171432793140411
################### EVAL ######################
Eval loss:528.7589721679688
epoch: 6, iter: 36000, loss:0.12859231233596802
################### EVAL ######################
Eval loss:552.85009765625
epoch: 7, iter: 38000, loss:0.07663708925247192
################### EVAL ######################
Eval loss:638.7730712890625
epoch: 7, iter: 40000, loss:0.08320281654596329
################### EVAL ######################
Eval loss:590.3145141601562
epoch: 7, iter: 42000, loss:0.13373945653438568
################### EVAL ######################
Eval loss:600.3804931640625
epoch: 8, iter: 44000, loss:0.10767394304275513
################### EVAL ######################
Eval loss:738.4500732421875
epoch: 8, iter: 46000, loss:0.13829460740089417
################### EVAL ######################
Eval loss:678.6792602539062
epoch: 9, iter: 48000, loss:0.06502832472324371
################### EVAL ######################
Eval loss:801.2380981445312
epoch: 9, iter: 50000, loss:0.12131325900554657
################### EVAL ######################
Eval loss:790.554931640625
epoch: 9, iter: 52000, loss:0.09517938643693924
################### EVAL ######################
Eval loss:753.604736328125
############################## Training End. ##############################
################### TEST ######################
Recall 0.0443-0.0708
NDCG 0.0185-0.0245
yelp correct training
arguments: Namespace(batch_size=1024, dataset='yelp', drop_rate=0.2, dropout=0.0, epochs=10, eval_freq=2000, exponent=1, factor_num=32, gpu='1', lr=0.001, model='NeuMF-end', num_gradual=30000, num_layers=3, num_ng=1, out=True, top_k=[50, 100]) 
config model NeuMF-end
config data path ../data/yelp/
config model path /home/hezhuangzhuang/DenoisingRec/T_CE/models/yelp/
user, item num
45548 57396
data loaded! user_num:45548, item_num:57396 train_data_len:1672520 test_user_num:45525
epoch: 0, iter: 2000, loss:0.5426334142684937
################### EVAL ######################
Eval loss:229.900146484375
epoch: 1, iter: 4000, loss:0.3720168471336365
################### EVAL ######################
Eval loss:169.5995330810547
epoch: 1, iter: 6000, loss:0.31729236245155334
################### EVAL ######################
Eval loss:152.0457763671875
epoch: 2, iter: 8000, loss:0.2571025788784027
################### EVAL ######################
Eval loss:154.7969970703125
epoch: 3, iter: 10000, loss:0.204490065574646
################### EVAL ######################
Eval loss:180.46180725097656
epoch: 3, iter: 12000, loss:0.20401406288146973
################### EVAL ######################
Eval loss:179.92372131347656
epoch: 4, iter: 14000, loss:0.1676013320684433
################### EVAL ######################
Eval loss:229.15567016601562
epoch: 4, iter: 16000, loss:0.14405818283557892
################### EVAL ######################
Eval loss:221.64816284179688
epoch: 5, iter: 18000, loss:0.12386471033096313
################### EVAL ######################
Eval loss:277.4385070800781
epoch: 6, iter: 20000, loss:0.08785204589366913
################### EVAL ######################
Eval loss:334.40625
epoch: 6, iter: 22000, loss:0.10509374737739563
################### EVAL ######################
Eval loss:323.8102111816406
epoch: 7, iter: 24000, loss:0.13812744617462158
################### EVAL ######################
Eval loss:381.5446472167969
epoch: 7, iter: 26000, loss:0.1014455258846283
################### EVAL ######################
Eval loss:366.7802734375
epoch: 8, iter: 28000, loss:0.07615607976913452
################### EVAL ######################
Eval loss:414.6835632324219
epoch: 9, iter: 30000, loss:0.08143654465675354
################### EVAL ######################
Eval loss:501.1678466796875
epoch: 9, iter: 32000, loss:0.08242183923721313
################### EVAL ######################
Eval loss:468.7750244140625
############################## Training End. ##############################
################### TEST ######################
Recall 0.0489-0.0831
NDCG 0.0192-0.0269
